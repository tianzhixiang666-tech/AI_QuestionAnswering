import os
import re
import json
import warnings
import base64
import time
import urllib.parse
import http.client
from flask import Flask, render_template, request, jsonify
from werkzeug.utils import secure_filename
from volcenginesdkarkruntime import Ark

# ç¦ç”¨å†—ä½™è­¦å‘Š
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
warnings.filterwarnings('ignore')

# ========== è±†åŒ…APIé…ç½® ==========
ARK_API_KEY = "a3560ff1-1d8d-49ba-92a7-7c89a9ec18d4" 
ARK_BASE_URL = "https://ark.cn-beijing.volces.com/api/v3"
ARK_MODEL = "doubao-seed-1-6-lite-251015" 
ARK_IMAGE_MODEL = "doubao-seedream-4-5-251128" 
ARK_VIDEO_MODEL = "doubao-seedance-1-5-pro-251215" 

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = Ark(base_url=ARK_BASE_URL, api_key=ARK_API_KEY)

# ========== æ–‡ä»¶é…ç½® ==========
UPLOAD_FOLDER = '../tmp/uploads'
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'webp'}
MAX_FILE_SIZE = 5 * 1024 * 1024 
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# æ¨¡å‹è·¯å¾„
TEXT_CATEGORY_MODEL_PATH = '../tmp/text_category_model.h5'
SENTIMENT_MODEL_PATH = '../tmp/sentiment_model.h5'
SENTIMENT_DICTS_PATH = '../tmp/sentiment_dicts.csv'
VOCAB_DIR = '../data/cnews.vocab.txt'

# å…¨å±€æ¨¡å‹å˜é‡
_sentiment_dicts = None
_sentiment_model = None
_translation_model_loaded = False

# ========== å·¥å…·å‡½æ•° ==========
def allowed_file(filename):
    """ç²¾ç®€ç‰ˆï¼šæ ¡éªŒæ–‡ä»¶æ ¼å¼"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def clean_invalid_chars(text):
    """ä¿®å¤ç‰ˆï¼šæ¸…ç†éæ³•å­—ç¬¦"""
    if not text:
        return ""
    control_chars = re.compile(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]')
    return control_chars.sub(' ', text).strip()

def normalize_text(text):
    """ä¿®å¤ç‰ˆï¼šæ–‡æœ¬æ ¼å¼è§„èŒƒåŒ–"""
    if not text:
        return ""
    text = clean_invalid_chars(text)
    try:
        text = json.loads(f'"{text}"')
    except:
        pass
    text = text.replace('\n', '<br>')
    text = text.replace('ã€€', ' ')
    text = re.sub(r'[\u200b\u200c\u200d\r]', '', text)
    text = re.sub(r'\*\*(.*?)\*\*', r'<b>\1</b>', text)
    
    punct_map = {
        ',': 'ï¼Œ', '.': 'ã€‚', '?': 'ï¼Ÿ', '!': 'ï¼',
        ':': 'ï¼š', ';': 'ï¼›', '(': 'ï¼ˆ', ')': 'ï¼‰',
        '[': 'ã€', ']': 'ã€‘'
    }
    for en, cn in punct_map.items():
        text = text.replace(en, cn)
    
    text = re.sub(r'(\d+)ã€‚(\d+)', r'\1.\2', text)
    text = re.sub(r'(\d+\.\d+)ã€‚(\d+)', r'\1.\2', text)
    
    return text

def image_to_base64(image_path):
    """ä¿®å¤ç‰ˆï¼šå›¾ç‰‡è½¬base64"""
    try:
        with open(image_path, 'rb') as f:
            image_data = f.read()
            base64_data = base64.b64encode(image_data).decode('utf-8')
            
            ext = image_path.rsplit('.', 1)[1].lower()
            mime_types = {
                'png': 'image/png',
                'jpg': 'image/jpeg',
                'jpeg': 'image/jpeg',
                'gif': 'image/gif',
                'webp': 'image/webp'}
            mime_type = mime_types.get(ext, 'image/jpeg')
            
            return f"data:{mime_type};base64,{base64_data}"
    except Exception as e:
        print(f"å›¾ç‰‡è½¬æ¢å¤±è´¥ï¼š{str(e)}")
        return None

def markdown_to_normal(text):
    """æ–°å¢ï¼šMarkdownæ ¼å¼è½¬æ­£å¸¸æ˜¾ç¤º"""
    if not text: return ""
    
    text = re.sub(r'^#{1,4}\s*(.*?)$', r'\1', text, flags=re.MULTILINE)
    text = re.sub(r'\*\*(.*?)\*\*', r'<b>\1</b>', text)
    text = re.sub(r'\*(.*?)\*', r'<i>\1</i>', text)
    text = re.sub(r'^\*\s*(.*?)$', r'â€¢ \1', text, flags=re.MULTILINE)
    
    return text

def get_fresh_video_url(task_id):
    """å®Œæ•´ç‰ˆï¼šåˆ·æ–°URLåŠŸèƒ½"""
    try:
        get_result = client.content_generation.tasks.get(task_id=task_id)
        if get_result.status == "succeeded":
            return get_result.content.video_url
        return None
    except Exception as e:
        print(f"åˆ·æ–°è§†é¢‘URLå¤±è´¥ï¼š{e}")
        return None

def format_analysis(results):
    '''ä¿®å¤ç‰ˆï¼šæ ¼å¼åŒ–åˆ†æç»“æœä¸ºHTMLï¼ˆç»Ÿä¸€æ˜¾ç¤ºï¼‰'''
    if not results:
        return ""
    
    html = '<div class="analysis-section">'
    html += '<div class="analysis-title">ğŸ” æ™ºèƒ½åˆ†æ</div>'
    
    # æ–‡æœ¬åˆ†ç±»
    if 'category' in results:
        cat = results['category']
        html += f'<div class="analysis-item">ğŸ“Œ <b>æ–‡æœ¬åˆ†ç±»ï¼š</b>{cat["label"]} <span style="color:#4CAF50;">(ç½®ä¿¡åº¦ï¼š{cat["score"]:.2f})</span></div>'
    
    # æƒ…æ„Ÿåˆ†æ
    if 'sentiment' in results:
        sent = results['sentiment']
        emoji = {'positive': 'ğŸ˜Š', 'negative': 'ğŸ˜¢', 'neutral': 'ğŸ˜'}.get(sent['label'], 'â¤ï¸')
        html += f'<div class="analysis-item">{emoji} <b>æƒ…æ„Ÿå€¾å‘ï¼š</b>{sent["label"]} <span style="color:#4CAF50;">(ç½®ä¿¡åº¦ï¼š{sent["score"]:.2f})</span></div>'
    
    # å…³é”®è¯æå–
    if 'keywords' in results and results['keywords']:
        html += '<div class="analysis-item">ğŸ”‘ <b>å…³é”®è¯ï¼š</b>'
        keywords_list = []
        for word, weight in results['keywords'][:5]:
            keywords_list.append(f'<span class="keyword-inline">{word}</span>')
        html += ' '.join(keywords_list)
        html += '</div>'
    
    # æ–‡æœ¬æ‘˜è¦
    if 'summary' in results and results['summary']:
        summary_text = results['summary']
        if len(summary_text) > 100:
            summary_text = summary_text[:100] + '...'
        html += f'<div class="analysis-item">ğŸ“ <b>æ–‡æœ¬æ‘˜è¦ï¼š</b>{summary_text}</div>'
    
    # å‘½åå®ä½“è¯†åˆ«
    if 'entities' in results and results['entities']:
        entities = results['entities']
        entity_parts = []
        
        if entities.get('person'):
            entity_parts.append(f'ğŸ‘¤äººå: {", ".join(entities["person"][:3])}')
        if entities.get('location'):
            entity_parts.append(f'ğŸ“åœ°å: {", ".join(entities["location"][:3])}')
        if entities.get('organization'):
            entity_parts.append(f'ğŸ¢æœºæ„: {", ".join(entities["organization"][:3])}')
        if entities.get('time'):
            entity_parts.append(f'â°æ—¶é—´: {", ".join(entities["time"][:2])}')
        
        if entity_parts:
            html += '<div class="analysis-item">ğŸ·ï¸ <b>å®ä½“è¯†åˆ«ï¼š</b><br>'
            html += '<br>'.join(entity_parts)
            html += '</div>'
    
    html += '</div>'
    return html

# ========== æ¨¡å‹åˆå§‹åŒ– ==========
def init_models():
    """ä¿®å¤ç‰ˆï¼šåˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹"""
    global _sentiment_dicts, _sentiment_model, _translation_model_loaded
    print("=" * 50)
    print("ç³»ç»Ÿåˆå§‹åŒ–ä¸­...")
    print("=" * 50)
    
    try:
        # 1. æ£€æŸ¥æ–‡æœ¬åˆ†ç±»æ¨¡å‹
        if os.path.exists(TEXT_CATEGORY_MODEL_PATH):
            print("âœ“ æ–‡æœ¬åˆ†ç±»æ¨¡å‹å·²å°±ç»ª")
        else:
            print("âœ— æ–‡æœ¬åˆ†ç±»æ¨¡å‹ä¸å­˜åœ¨")
        
        # 2. åŠ è½½æƒ…æ„Ÿåˆ†ææ¨¡å‹
        if os.path.exists(SENTIMENT_MODEL_PATH):
            from sentiment_analysis import load_sentiment_deps
            _sentiment_dicts, _sentiment_model = load_sentiment_deps(
                SENTIMENT_MODEL_PATH, SENTIMENT_DICTS_PATH)
            if _sentiment_dicts is not None:
                print("âœ“ æƒ…æ„Ÿåˆ†ææ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                print("âœ— æƒ…æ„Ÿåˆ†ææ¨¡å‹åŠ è½½å¤±è´¥")
        else:
            print("âœ— æƒ…æ„Ÿåˆ†ææ¨¡å‹ä¸å­˜åœ¨")
        
        # 3. åŠ è½½æœºå™¨ç¿»è¯‘æ¨¡å‹
        try:
            from machine_translation import load_translation_model
            load_translation_model()
            _translation_model_loaded = True
            print("âœ“ æœºå™¨ç¿»è¯‘æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            _translation_model_loaded = False
            print(f"âœ— æœºå™¨ç¿»è¯‘æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}")
        
        # 4. åˆå§‹åŒ–æ–°å¢çš„NLPæ¨¡å—
        try:
            from keyword_extraction import init_jieba
            init_jieba()
            print("âœ“ å…³é”®è¯æå–æ¨¡å—å·²å°±ç»ª")
        except Exception as e:
            print(f"âœ— å…³é”®è¯æå–æ¨¡å—åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
        
        print("=" * 50)
        print("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
        print("=" * 50)
    except Exception as e:
        print(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")

# ========== æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ==========
def generate_image(prompt):
    """ç²¾ç®€ç‰ˆï¼šç”Ÿæˆå›¾ç‰‡"""
    try:
        resp = client.images.generate(
            model=ARK_IMAGE_MODEL, prompt=prompt, size="2K", response_format="url"
        )
        if resp and resp.data:
            url = resp.data[0].url
            safe_prompt = normalize_text(prompt)
            return f'<b>ğŸ¨ å›¾åƒå·²ç”Ÿæˆ</b><br><img src="{url}" class="message-image" style="max-width:100%; border-radius:8px; margin-top:10px;"><br><small>æç¤ºè¯ï¼š{safe_prompt}</small>'
        return "âŒ å›¾åƒç”Ÿæˆå¤±è´¥"
    except Exception as e:
        return f"âŒ å›¾åƒç”Ÿæˆé”™è¯¯ï¼š{str(e)}"

def generate_video(prompt):
    """èåˆç‰ˆï¼šç”Ÿæˆè§†é¢‘"""
    try:
        create_result = client.content_generation.tasks.create(
            model=ARK_VIDEO_MODEL,
            content=[{"type": "text", "text": f"{prompt} --duration 5 --watermark true"}]
        )
        task_id = create_result.id
        
        for _ in range(100):
            time.sleep(5)
            get_result = client.content_generation.tasks.get(task_id=task_id)
            status = get_result.status
            
            if status == "succeeded":
                video_url = get_result.content.video_url
                if video_url:
                    res_html = (
                        f'<b>ğŸ¬ è§†é¢‘ç”ŸæˆæˆåŠŸ</b><br>'
                        f'<div>åˆ†è¾¨ç‡ï¼š{getattr(get_result, "resolution", "N/A")} | æ—¶é•¿ï¼š{getattr(get_result, "duration", "5")}ç§’</div>'
                        f'<div style="color:#ff6600; font-size:12px; margin:8px 0;">âš ï¸ è§†é¢‘é“¾æ¥æœ‰æ•ˆæœŸ24å°æ—¶ï¼Œè¿‡æœŸå¯åˆ·æ–°</div>'
                        f'<a href="{video_url}" target="_blank" style="display:inline-block; margin-top:5px; padding:8px 15px; background:#4CAF50; color:white; border-radius:4px; text-decoration:none;">ç‚¹å‡»æ‰“å¼€å¹¶ä¸‹è½½è§†é¢‘</a>'
                        f'<div style="font-size:12px; margin-top:8px;">ä»»åŠ¡IDï¼š<code>{task_id}</code>ï¼ˆåˆ·æ–°é“¾æ¥ç”¨ï¼‰</div>'
                    )
                    return res_html
                return "âŒ æœªè·å–åˆ°è§†é¢‘é“¾æ¥"
            
            elif status == "failed":
                return f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼š{getattr(get_result, 'error', 'æœªçŸ¥é”™è¯¯')}"
                
        return f"âš ï¸ ä»»åŠ¡è¶…æ—¶ï¼ˆæœ€å¤§ç­‰å¾…100æ¬¡ï¼‰ï¼Œè¯·ç¨åæŸ¥è¯¢ ID: {task_id}"
    except Exception as e:
        return f"âŒ è§†é¢‘ç”Ÿæˆå¯åŠ¨å¤±è´¥ï¼š{str(e)}"

def chat(sentence='', image_paths=None, **switches):
    """èåˆç‰ˆï¼šæ ¸å¿ƒå¯¹è¯åŠŸèƒ½ï¼ˆä¿®å¤ç‰ˆï¼šæ­£ç¡®æ”¶é›†å’Œæ˜¾ç¤ºåˆ†æç»“æœï¼‰"""
    try:
        # åŠŸèƒ½åˆ†å‘ï¼ˆç”Ÿæˆå›¾ç‰‡/è§†é¢‘ï¼‰
        if switches.get('enable_image_gen') and "ç”Ÿæˆå›¾ç‰‡" in sentence:
            prompt = re.sub(r'ç”Ÿæˆå›¾ç‰‡[:ï¼š]?', '', sentence).strip()
            return generate_image(prompt)
            
        if switches.get('enable_video_gen') and "ç”Ÿæˆè§†é¢‘" in sentence:
            prompt = re.sub(r'ç”Ÿæˆè§†é¢‘[:ï¼š]?', '', sentence).strip()
            return generate_video(prompt)

        # ========== æ”¶é›†æ‰€æœ‰åˆ†æç»“æœ ==========
        analysis_results = {}
        
        # æ¨¡å—1ï¼šæ–‡æœ¬åˆ†ç±»
        if switches.get('enable_category') and sentence:
            try:
                from text_categorization import predict_text_category
                cat_label, cat_score = predict_text_category(
                    text=sentence,
                    model_path=TEXT_CATEGORY_MODEL_PATH,
                    vocab_dir=VOCAB_DIR
                )
                analysis_results['category'] = {
                    'label': cat_label,
                    'score': cat_score
                }
            except Exception as e:
                print(f"æ–‡æœ¬åˆ†ç±»å¤±è´¥ï¼š{str(e)}")
        
        # æ¨¡å—2ï¼šæƒ…æ„Ÿåˆ†æ
        if switches.get('enable_sentiment') and sentence:
            try:
                from sentiment_analysis import predict_sentiment
                sentiment_label, sentiment_score = predict_sentiment(
                    text=sentence,
                    dicts=_sentiment_dicts,
                    model=_sentiment_model
                )
                analysis_results['sentiment'] = {
                    'label': sentiment_label,
                    'score': sentiment_score
                }
            except Exception as e:
                print(f"æƒ…æ„Ÿåˆ†æå¤±è´¥ï¼š{str(e)}")
        
        # æ¨¡å—3ï¼šå…³é”®è¯æå–ï¼ˆä¿®å¤ï¼šæ­£ç¡®ä¿å­˜ï¼‰
        if switches.get('enable_keywords') and sentence and len(sentence) >= 1:
            try:
                from keyword_extraction import extract_keywords_hybrid
                keywords = extract_keywords_hybrid(sentence, topK=5)
                if keywords:
                    analysis_results['keywords'] = keywords  # ç›´æ¥ä¿å­˜åˆ—è¡¨
            except Exception as e:
                print(f"å…³é”®è¯æå–å¤±è´¥ï¼š{str(e)}")
        
        # æ¨¡å—4ï¼šæ–‡æœ¬æ‘˜è¦ï¼ˆä¿®å¤ï¼šæ­£ç¡®ä¿å­˜ï¼‰
        if switches.get('enable_summary') and sentence and len(sentence) >= 50:
            try:
                from text_summarization import extract_summary_textrank
                summary = extract_summary_textrank(sentence, ratio=0.4)
                if summary and summary != "æ–‡æœ¬è¿‡çŸ­ï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦":
                    analysis_results['summary'] = summary  # ç›´æ¥ä¿å­˜æ–‡æœ¬
            except Exception as e:
                print(f"æ–‡æœ¬æ‘˜è¦å¤±è´¥ï¼š{str(e)}")
        
        # æ¨¡å—5ï¼šå‘½åå®ä½“è¯†åˆ«ï¼ˆä¿®å¤ï¼šæ­£ç¡®ä¿å­˜ï¼‰
        if switches.get('enable_ner') and sentence:
            try:
                from named_entity_recognition import extract_all_entities
                entities = extract_all_entities(sentence)
                # è¿‡æ»¤ç©ºå®ä½“
                filtered_entities = {k: v for k, v in entities.items() if v}
                if filtered_entities:
                    analysis_results['entities'] = filtered_entities  # ä¿å­˜å­—å…¸
            except Exception as e:
                print(f"å‘½åå®ä½“è¯†åˆ«å¤±è´¥ï¼š{str(e)}")
        
        # æ¨¡å—6ï¼šæœºå™¨ç¿»è¯‘
        zh2en_pattern = re.compile(r'ä¸­è¯‘è‹±[:ï¼š]?\s*(.+?)($|ï¼›|ã€‚|ï¼Œ|ï¼|ï¼Ÿ)|ç¿»è¯‘[:ï¼š]?\s*(.+?)($|ï¼›|ã€‚|ï¼Œ|ï¼|ï¼Ÿ)', re.IGNORECASE)
        translate_match = zh2en_pattern.search(sentence) if sentence else None
        
        if switches.get('enable_translation') and translate_match and _translation_model_loaded:
            try:
                from machine_translation import machine_translate
                translate_text = translate_match.group(1) or translate_match.group(3)
                translate_text = translate_text.strip() if translate_text else sentence
                
                if translate_text:
                    end_punct = 'ã€‚ï¼ï¼Ÿï¼›ï¼Œ'
                    if not translate_text or translate_text[-1] not in end_punct:
                        translate_text += 'ã€‚'
                    
                    translate_result = machine_translate(translate_text,
                                                         src_lang="zh",
                                                         tgt_lang="en")
                    
                    # æ„å»ºç¿»è¯‘å›å¤
                    res_msg = f"<b>ã€ä¸­è¯‘è‹±ç»“æœã€‘</b><br>{translate_result}"
                    
                    # è¿½åŠ åˆ†æç»“æœ
                    if analysis_results:
                        res_msg += "<br><br>" + format_analysis(analysis_results)
                    
                    return normalize_text(res_msg)
            except Exception as e:
                print(f"ç¿»è¯‘å¤±è´¥ï¼š{str(e)}")
                return normalize_text(f"ç¿»è¯‘æœåŠ¡æš‚æ—¶ä¸å¯ç”¨<br>é”™è¯¯ï¼š{str(e)}")
        
        # ========== æ­£å¸¸å¯¹è¯é€»è¾‘ ==========
        user_content = []
        if sentence:
            user_content.append({"type": "text", "text": sentence})
        if image_paths and len(image_paths) > 0:
            for img_path in image_paths:
                base64_image = image_to_base64(img_path)
                if base64_image:
                    user_content.append({
                        "type": "image_url",
                        "image_url": {"url": base64_image}
                    })
        
        if not user_content:
            return normalize_text("è¯·è¾“å…¥æ¶ˆæ¯æˆ–ä¸Šä¼ å›¾ç‰‡ï½")
        
        # æ·±åº¦æ€è€ƒåŠŸèƒ½
        messages = [{"role": "user", "content": user_content}]
        if switches.get('enable_deep_think') and sentence:
            messages.insert(0, {
                "role": "system",
                "content": "è¯·åŸºäºç”¨æˆ·çš„é—®é¢˜è¿›è¡Œæ·±åº¦ã€å…¨é¢çš„åˆ†æï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š1. æ ¸å¿ƒé—®é¢˜æ‹†è§£ï¼›2. å¤šè§’åº¦åˆ†æï¼›3. æ½œåœ¨é€»è¾‘ï¼›4. å…·ä½“è§£å†³æ–¹æ¡ˆ/å»ºè®®ã€‚å›ç­”éœ€æ¡ç†æ¸…æ™°ã€é€»è¾‘ä¸¥è°¨ã€‚"
            })

        # è°ƒç”¨è±†åŒ…API
        comp = client.chat.completions.create(
            model=ARK_MODEL,
            messages=messages
        )
        
        # å¤„ç†å›å¤æ ¼å¼
        raw_res = comp.choices[0].message.content
        markdown_res = markdown_to_normal(raw_res)
        final_res = normalize_text(markdown_res)
        
        # è¿½åŠ åˆ†æç»“æœï¼ˆç»Ÿä¸€æ˜¾ç¤ºï¼‰
        if analysis_results:
            final_res += "<br><br>" + format_analysis(analysis_results)
        
        # æ·±åº¦æ€è€ƒæ ‡è¯†
        if switches.get('enable_deep_think'):
            final_res = f'<div style="color:#2196F3; font-size:12px; margin-bottom:8px;">ğŸ’¡ å·²å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼</div>' + final_res
        
        return final_res
        
    except Exception as e:
        return f"âŒ å¯¹è¯é”™è¯¯ï¼š{str(e)}"

# ========== Flask è·¯ç”± ==========
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = MAX_FILE_SIZE

@app.route('/refresh_video_url', methods=['POST'])
def refresh_video_url():
    """åˆ·æ–°è¿‡æœŸçš„è§†é¢‘URL"""
    try:
        task_id = request.form.get('task_id', '').strip()
        if not task_id:
            return jsonify({'text': "âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„ä»»åŠ¡ID"})
        
        fresh_url = get_fresh_video_url(task_id)
        if fresh_url:
            res_html = (
                f'<b>âœ… URLåˆ·æ–°æˆåŠŸ</b><br>'
                f'<div style="color:#ff6600; font-size:12px; margin:8px 0;">âš ï¸ æ–°é“¾æ¥æœ‰æ•ˆæœŸ24å°æ—¶</div>'
                f'<a href="{fresh_url}" target="_blank" style="display:inline-block; padding:8px 15px; background:#4CAF50; color:white; border-radius:4px; text-decoration:none;">ç‚¹å‡»ä¸‹è½½è§†é¢‘</a>'
            )
            return jsonify({'text': res_html})
        else:
            return jsonify({'text': "âŒ åˆ·æ–°å¤±è´¥ï¼šä»»åŠ¡ä¸å­˜åœ¨/çŠ¶æ€å¼‚å¸¸"})
    except Exception as e:
        return jsonify({'text': f"âŒ åˆ·æ–°URLå¤±è´¥ï¼š{str(e)}"})

@app.route('/message', methods=['POST'])
def reply():
    """ä¿®å¤ç‰ˆï¼šæ”¯æŒæ‰€æœ‰åŠŸèƒ½å¼€å…³"""
    msg = request.form.get('msg', '').strip()
    # æ•´åˆæ‰€æœ‰å¼€å…³
    switches = {
        k: request.form.get(k) == 'true' 
        for k in ['enable_image_gen', 'enable_video_gen', 'enable_sentiment', 
                 'enable_deep_think', 'enable_category', 'enable_translation',
                 'enable_keywords', 'enable_summary', 'enable_ner']
    }
    
    # å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡
    image_paths = []
    if 'images' in request.files:
        files = request.files.getlist('images')
        for file in files:
            if file and allowed_file(file.filename):
                filename = secure_filename(file.filename)
                timestamp = str(int(time.time() * 1000))
                filename = f"{timestamp}_{filename}"
                filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                file.save(filepath)
                image_paths.append(filepath)
                print(f"âœ“ å›¾ç‰‡å·²ä¿å­˜ï¼š{filepath}")
    
    if not msg and not image_paths:
        return jsonify({'text': normalize_text('è¯·è¾“å…¥å†…å®¹æˆ–ä¸Šä¼ å›¾ç‰‡ï½')})

    res_text = chat(msg, image_paths, **switches)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    for p in image_paths:
        try:
            if os.path.exists(p): 
                os.remove(p)
        except Exception as e:
            print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥ï¼š{e}")
        
    return jsonify({'text': res_text})

@app.route("/")
def index():
    return render_template('index.html')

if __name__ == '__main__':
    init_models()
    print("\nâœ… æœåŠ¡å¯åŠ¨æˆåŠŸï¼šhttp://127.0.0.1:8808")
    print("âš ï¸  ç”Ÿäº§ç¯å¢ƒè¯·å…³é—­debugæ¨¡å¼")
    app.run(host='127.0.0.1', port=8808, debug=False)